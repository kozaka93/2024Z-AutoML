{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "891f858402018045",
   "metadata": {},
   "source": [
    "# MedAId \n",
    "## Paczka umożliwiająca przewidywanie Stanu Pacjentów za Pomocą Narzędzi Klasyfikacyjnych \n",
    "#### Autorzy: Zofia Kamińska, Mateusz Deptuch, Karolina Dunal\n",
    "### Specyfikacja Narzędzia\n",
    "Nasze narzędzie jest stworzone z myślą o lekarzach, aby wspomóc ich w procesie podejmowania decyzji medycznych. Głównym celem jest analiza tabelarycznych danych pacjentów, takich jak wiek, waga, poziom cholesterolu, itp., w celu przewidywania:\n",
    "- Czy pacjent ma daną chorobę (klasyfikacja binarna).\n",
    "- Poziomu zaawansowania choroby (klasyfikacja wieloklasowa).\n",
    "- Ryzyka zgonu pacjenta (klasyfikacja binarna).\n",
    "\n",
    "### Kluczowe Funkcjonalności\n",
    "- Obsługa zarówno klasyfikacji binarnej, jak i wieloklasowej.\n",
    "- Zautomatyzowane przetwarzanie danych: oczyszczanie, analiza wstępna i przygotowanie cech.\n",
    "- Interpretacja wyników modeli za pomocą narzędzi takich jak SHAP.\n",
    "- Porównanie wyników różnych modeli ML z różnymi metrykami (np. dokładność, ROC-AUC, czułość, specyficzność).\n",
    "\n",
    "### Grupa Docelowa\n",
    "Grupą docelową są lekarze i personel medyczny. Narzędzie jest przeznaczone dla użytkowników, którzy:\n",
    "- Chcą wykorzystać dane pacjentów w celu lepszego podejmowania decyzji medycznych.\n",
    "- Nie posiadają zaawansowanej wiedzy z zakresu programowania czy uczenia maszynowego.\n",
    "- Potrzebują intuicyjnych wizualizacji i interpretacji wyników modeli.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c5d3ad7be90ddd2",
   "metadata": {},
   "source": [
    "# Przegląd Istniejących Rozwiązań\n",
    "Poniżej przedstawiono istniejące narzędzia o podobnej funkcjonalności:\n",
    "\n",
    "### 1. Pharm-AutoML\n",
    "- **Opis**: Narzędzie skoncentrowane na analizie danych biomedycznych z użyciem AutoML. Umożliwia analizę genomu, farmakogenomiki i danych biomarkerów.\n",
    "- **Zalety**: Specjalizacja w biomedycynie, zintegrowane modele biomarkerowe.\n",
    "- **Ograniczenia**: Ograniczona aplikacja do tabelarycznych danych klinicznych.\n",
    "\n",
    "### 2. Cardea (MIT)\n",
    "- **Opis**: Platforma uczenia maszynowego skupiona na przewidywaniu wyników pacjentów na podstawie danych klinicznych, takich jak elektroniczne kartoteki zdrowotne (EHR).\n",
    "- **Zalety**: Doskonała integracja z EHR, zastosowanie zaawansowanych modeli.\n",
    "- **Ograniczenia**: Skupienie na EHR może utrudnić zastosowanie w prostych danych tabelarycznych.\n",
    "\n",
    "### 3. AutoPrognosis\n",
    "- **Opis**: AutoPrognosis to zaawansowana platforma AutoML, która automatycznie optymalizuje modele zdrowotne i przetwarza dane medyczne, oferując szeroki zakres analiz, w tym klasyfikację, regresję oraz analizę przeżycia. Umożliwia pełną personalizację procesów i wybór algorytmów.\n",
    "- **Zalety**: Oferuje zaawansowane możliwości i dużą elastyczność, wspiera różnorodne modele i dostarcza narzędzia interpretacyjne, co czyni go idealnym rozwiązaniem dla specjalistów z zaawansowanymi potrzebami.\n",
    "- **Ograniczenia**: Choć ma szerokie możliwości, jego obsługa jest bardziej skomplikowana i wymaga większej wiedzy technicznej, co może czasem być wyzwaniem w praktyce.\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.95      0.91      0.93        43\n",
    "           1       0.95      0.97      0.96        71\n",
    "\n",
    "    accuracy                           0.95       114\n",
    "   macro avg       0.95      0.94      0.94       114\n",
    "weighted avg       0.95      0.95      0.95       114\n",
    "```\n",
    "\n",
    "### 4. MLJAR\n",
    "- **Opis**: Narzędzie AutoML obsługujące dane tabelaryczne w wielu dziedzinach, w tym medycynie.\n",
    "- **Zalety**: Uniwersalność, przyjazne raporty, intuicyjne w obsłudze.\n",
    "- **Ograniczenia**: Brak medycznej specjalizacji, co może wpłynąć na interpretowalność w kontekście klinicznym.\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.98      0.95      0.96        43\n",
    "           1       0.97      0.99      0.98        71\n",
    "\n",
    "    accuracy                           0.97       114\n",
    "   macro avg       0.97      0.97      0.97       114\n",
    "weighted avg       0.97      0.97      0.97       114\n",
    "```\n",
    "\n",
    "### Porównanie z Naszym Narzędziem\n",
    "Nasze narzędzie jest unikalne dzięki prostocie obsługi, wymagając minimalnego kodowania, co sprawia, że jest idealne dla użytkowników bez zaawansowanej wiedzy technicznej, a także zoptymalizowane pod kątem medycznych danych tabelarycznych, co czyni je bardziej dostosowanym do analiz biomedycznych w porównaniu do bardziej ogólnych narzędzi W przeciwieństwie do MLJAR, nasze wyniki są dostosowane do potrzeb lekarzy. Różnimy się też od Cardea i Pharm-AutoML, które mają węższy zakres zastosowań. W porównaniu do AutoPrognosis, które oferuje więcej zaawansowanych funkcji i możliwości, nasze narzędzie jest prostsze w obsłudze i bardziej intuicyjne, co ułatwia jego wykorzystanie.\n",
    "Przy podobnym czasie treningu nasze narzędzie osiąga zauważalnie lepsze wyniki niż AutoPrognosis. MLjar z kolei wypada lekko lepiej/porównywalnie z naszym rozwiązaniem.\n",
    "```\n",
    "              precision    recall  f1-score   support\n",
    "\n",
    "           0       0.93      0.98      0.95        43\n",
    "           1       0.99      0.96      0.97        71\n",
    "\n",
    "    accuracy                           0.96       114\n",
    "   macro avg       0.96      0.97      0.96       114\n",
    "weighted avg       0.97      0.96      0.97       114\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcd32d103b8c022b",
   "metadata": {},
   "source": [
    "## Architektura Narzędzia\n",
    "### Struktura folderów:\n",
    "- `data/` - dane wejściowe\n",
    "- `medaid/` - kod źródłowy narzędzia\n",
    "- `tests/` - testy jednostkowe\n",
    "\n",
    "## Przepływ Przetwarzania Danych:\n",
    "### Paczka MedAId składa się z trzech głównych komponentów:\n",
    "1. **Przetwarzanie Danych** (`preprocessing)/`: Wczytywanie danych, oczyszczanie, kodowanie zmiennych kategorycznych, podział na zbiór treningowy i testowy. **(można bardzije szczegółowo opisać)**\n",
    "\n",
    "2. **Modelowanie**(`training/`): Tworzenie modeli klasyfikacyjnych, trenowanie, ocena i porównanie modeli, zapisanie modeli do pliku. **(można bardzije szczegółowo opisać)**\n",
    "\n",
    "3. **Interpretacja Wyników**(`reporting/`): Tworzenie wizualizacji wyników modeli, generowanie raportu, analiza SHAP, porównanie metryk. \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "106118ee",
   "metadata": {},
   "source": [
    "### `preprocessing/`\n",
    "Moduł odpowiedzialny za kompleksowy proces przetwarzania danych, który obejmuje następujące etapy: obsługę formatów numerycznych, usuwanie kolumn tekstowych, imputację brakujących danych, kodowanie zmiennych kategorycznych oraz skalowanie cech. W tej klasie integrujemy różne komponenty przetwarzania danych w jeden pipeline, który umożliwia jednoczesne zarządzanie wszystkimi wymaganymi etapami.\n",
    "\n",
    "#### `preprocessing.py`\n",
    "#### Etapy przetwarzania:\n",
    "1. **Obsługa formatów numerycznych**  \n",
    "   Funkcja `handle_numeric_format()` w klasie `NumericCommaHandler` zajmuje się konwersją liczb zapisanych w formacie z przecinkiem (np. `1,000`) na standardowy format numeryczny.\n",
    "   \n",
    "2. **Usuwanie kolumn tekstowych**  \n",
    "   Wykorzystywana jest funkcjonalność klasy `ColumnRemover`, która identyfikuje i usuwa kolumny tekstowe na podstawie określonych progów (np. gdy brakujące dane w kolumnie przekraczają zdefiniowaną granicę).\n",
    "   \n",
    "3. **Imputacja brakujących danych**  \n",
    "   Funkcja imputacji opiera się na różnych metodach, takich jak regresja liniowa (w klasie `Imputer`) i Random Forest. Progi korelacji są ustawiane do wykorzystania odpowiednich algorytmów imputacji w zależności od korelacji kolumn z innymi zmiennymi.\n",
    "   \n",
    "4. **Kodowanie zmiennych kategorycznych**  \n",
    "   Zmienne kategoryczne, w tym kolumna celu, są kodowane przez klasę `Encoder` przy użyciu różnych metod kodowania, w tym `LabelEncoder` i `OneHotEncoder`.\n",
    "   \n",
    "5. **Skalowanie cech**  \n",
    "   Funkcja `scale()` w klasie `Scaler` skaluje numeryczne kolumny w DataFrame. Zależnie od rozkładu danych (normalny lub skośny), używana jest standardyzacja (przy rozkładzie normalnym) lub normalizacja (przy rozkładzie skośnym).\n",
    "\n",
    "#### Główne funkcje klasy `Preprocessing`:\n",
    "\n",
    "- **`__init__(target_column, path, imputer_lr_correlation_threshold, imputer_rf_correlation_threshold, categorical_threshold, removal_correlation_threshold)`**:  \n",
    "    Inicjalizuje obiekt klasy, ustalając parametry takie jak kolumna celu, progi korelacji i inne opcje konfiguracyjne. Tworzy instancje odpowiednich komponentów przetwarzania, takich jak `NumericCommaHandler`, `ColumnRemover`, `Encoder`, `Scaler`, `Imputer` i `PreprocessingCsv`.\n",
    "    **Opis parametrów:**\n",
    "    - `target_column` (str): nazwa kolumny celu.\n",
    "    - `path` (str): ścieżka do katalogu, w którym zostaną zapisane infromacje o przetwarzaniu.\n",
    "    - `imputer_lr_correlation_threshold` (float): próg korelacji dla imputacji przy użyciu regresji liniowej. \n",
    "    - `imputer_rf_correlation_threshold` (float): próg korelacji dla imputacji przy użyciu Random Forest. \n",
    "    - `categorical_threshold` (float): próg dla uznania kolumny za tekstową, która nie jest kategoryczna. Liczy się stosunek unikatowych wartości do wszystkich, jeśli jest wyższy niż próg, kolumna jest traktowana jako tekstowa i usuwana.\n",
    "    - `removal_correlation_threshold` (float): próg korelacji do usuwania kolumn silnie skorelowanych ze sobą (z wyjątkiem kolumny celu). Tylko jedna z grup skorelowanych kolumn pozostaje.\n",
    "\n",
    "\n",
    "- **`preprocess(dataframe)`**:  \n",
    "    Główna funkcja przetwarzania, która wykonuje wszystkie kroki pipeline. Przyjmuje DataFrame, przechodzi przez każdy etap przetwarzania, a na końcu zwraca przetworzony DataFrame. Po każdym etapie zapisuje szczegóły przetwarzania, takie jak usuwanie kolumn tekstowych, imputacja, kodowanie i skalowanie.\n",
    "\n",
    "- **`get_column_info()`**:  \n",
    "    Zwraca szczegóły dotyczące przetwarzania dla każdej kolumny, takie jak informacje o usuniętych kolumnach, zastosowanych metodach imputacji, kodowaniu i skalowaniu.\n",
    "\n",
    "- **`save_column_info(text_column_removal_info, imputation_info, encoding_info, scaling_info)`**:  \n",
    "    Zapisuje szczegóły przetwarzania do pliku CSV. Funkcja ta korzysta z klasy `PreprocessingCsv`, aby zapisać informacje o usuniętych kolumnach, imputacji, kodowaniu i skalowaniu.\n",
    "\n",
    "- **`get_target_encoding_info()`**:  \n",
    "    Zwraca informacje o metodzie kodowania dla kolumny celu.\n",
    "\n",
    "#### Szczegóły implementacji poszczególnych komponentów:\n",
    "Poniższe klasy i ich metody są zaimplementowane w oddzielnych plikach.\n",
    "\n",
    "- **`NumericCommaHandler`** - `numeric_format_handler.py`:  \n",
    "  Zajmuje się konwersją liczb zapisanych w formacie z przecinkiem (np. `1,000`) na format numeryczny, zapewniając spójność danych w DataFrame.\n",
    "\n",
    "- **`ColumnRemover`** - `column_removal.py`:  \n",
    "  Umożliwia usuwanie kolumn tekstowych, których wartości są nieistotne, na podstawie różnych kryteriów, takich jak ilość brakujących danych czy korelacja z kolumną celu.\n",
    "\n",
    "- **`Imputer`** - `imputer.py`:  \n",
    "  Przeprowadza imputację brakujących danych na podstawie różnych metod, takich jak regresja liniowa, Random Forest lub inne algorytmy, zależnie od korelacji z innymi zmiennymi.\n",
    "\n",
    "- **`Encoder`** - `encoder.py`:  \n",
    "  Koduje zmienne kategoryczne, w tym zmienną celu, przy użyciu `LabelEncoder` i `OneHotEncoder`, a także zapewnia przechowanie informacji o metodach kodowania i ich mapowaniach.\n",
    "\n",
    "- **`Scaler`** - `scaler.py`:  \n",
    "  Skaluje zmienne numeryczne, decydując o metodzie (standaryzacja lub normalizacja) w zależności od wykrytego rozkładu danych w kolumnach.\n",
    "\n",
    "- **`PreprocessingCsv`** - `preprocessing_info.py`:  \n",
    "  Zapisuje szczegóły przetwarzania do pliku CSV, umożliwiając późniejsze śledzenie zastosowanych metod oraz parametrów w procesie przetwarzania danych.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "320922a01c6350c3",
   "metadata": {},
   "source": [
    "### `training/`\n",
    "#### `medaid.py`:\n",
    "Moduł slużący do przeprowadzania treningu modeli i optymalizacji hipermarametrów.\n",
    "1. `__train(...)__`: tu dzieje się cały trening i optymalizacja hipermarametrów.\n",
    "2. `__search.py__`: definicje klas random i grid search, używanych przy trningu\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "efa8ceb33807be3e",
   "metadata": {},
   "source": [
    "### `reporting/`\n",
    "#### `plots.py`:\n",
    "Moduł do generowania wizualizacji wspierających analizę wyników modeli zapisywane odpowiednio w folderach wewnątrz głownego folderu `medaid#`:\n",
    "1. **`distribution_plots(aid)`**: Tworzy histogramy i wykresy słupkowe dla zmiennych wejściowych.\n",
    "2. **`correlation_plot(aid)`**: Generuje macierz korelacji oraz wykresy zależności cech od celu.\n",
    "3. **`make_confusion_matrix(aid)`**: Tworzy macierze konfuzji na zbiorze testowym dla każdego modelu.\n",
    "4. **`shap_feature_importance_plot(aid)`**: Wizualizuje ważność cech na podstawie SHAP.\n",
    "5. **`generate_supertree_visualizations(medaid, output_dir)`**: Tworzy interaktywne wizualizacje SuperTree dla modeli.\n",
    "6. **`makeplots(aid)`**: Uruchamia wszystkie powyższe funkcje, generując komplet wizualizacji.\n",
    "\n",
    "#### `mainreporter.py`:\n",
    "Klasa `MainReporter` generuje raport w formacie HTML z wynikami analizy danych i modeli. Raport zawiera szczegóły na temat danych, preprocesingu, rozkładów cech, macierzy korelacji, wyników modeli oraz ich szczegółowej analizy. Wygenerowany raport znajduje się w folderze `reports/` wewnątrz folderu `medaid#`.\n",
    "\n",
    "1. **`__init__(self, aid, path)`**: Konstruktor inicjalizuje ścieżkę do folderu z wynikami oraz obiekt `aid` zawierający dane i modele.\n",
    "2. **`is_nan(value)`**: Funkcja pomocnicza do sprawdzania, czy wartość jest NaN.\n",
    "3. **`generate_report()`**: Generuje raport HTML, który zawiera:\n",
    "   - Podstawowe informacje o danych (liczba wierszy, kolumn, unikalne klasy celu).\n",
    "   - Podgląd danych (pierwsze wiersze DataFrame).\n",
    "   - Szczegóły preprocesingu z pliku CSV.\n",
    "   - Rozkłady cech na wykresach.\n",
    "   - Analizę korelacji cech z celem oraz pełną macierz korelacji.\n",
    "   - Szczegóły użytych modeli i ich wyników (m.in. Accuracy, Precision, Recall, F1).\n",
    "   - Szczegóły modeli (np. macierz konfuzji, ważność cech, wizualizacja drzewa).\n",
    "   - Wizualizację drzewa dla modeli `DecisionTree` i `RandomForest`.\n",
    "\n",
    "#### `predictexplain.py`:\n",
    "Klasa `PredictExplainer` generuje raport wyjaśniający prognozę modelu na podstawie danych wejściowych zapisywany w folderze `medaid#`.\n",
    "1. **`__init__(self, medaid, model)`**: Inicjalizuje klasę `PredictExplainer`, przypisując obiekt `medaid` oraz model, a także wczytuje szczegóły przetwarzania wstępnego z pliku CSV.\n",
    "2. **`preprocess_input_data(self, input_data)`**: Przetwarza dane wejściowe zgodnie z zapisanymi szczegółami przetwarzania, stosując kodowanie one-hot, etykietowanie, imputację i skalowanie na podstawie wcześniejszych ustawień.\n",
    "3. **`analyze_prediction(self, prediction, target_column, prediction_proba)`**: Analizuje przewidywaną wartość dla docelowej cechy, porównuje ją z rozkładem w zbiorze danych i generuje raport klasyfikacji z uwzględnieniem wykresu ważności cech (SHAP) w przypadku klasyfikacji.\n",
    "4. **`generate_html_report(self, df, input_data)`**: Korzystając z pozostałych funkcji eneruje raport HTML porównujący dane wejściowe z danymi w zbiorze, analizuje przewidywania i generuje wykresy interpretowalności modelu.\n",
    "5. **`generate_viz(self, input_data)`**: Generuje wizualizacje dla danych wejściowych przy użyciu SHAP (dla większości modeli) lub LIME (dla modeli opartych na drzewach decyzyjnych).\n",
    "6. **`generate_shap_viz(self, input_data)`**: Generuje wizualizacje SHAP, w tym wykres siły dla pojedynczej prognozy oraz wykres podsumowujący dla całego zbioru danych, zapisując je jako pliki.\n",
    "7. **`generate_lime_viz(self, input_data)`**: Generuje wizualizacje LIME dla danych wejściowych, zapisując wykres wyjaśnienia do pliku HTML.\n",
    "8. **`predict_target(input_data)`**: Przetwarza dane wejściowe, dokonuje predykcji za pomocą modelu, analizuje wynik i generuje wizualizacje SHAP/LIME w celu zwiększenia interpretowalności.\n",
    "9. **`classify_and_analyze_features(df, input_data)`**:  Klasyfikuje cechy na typy binarne, kategoryczne tekstowe, kategoryczne numeryczne i ciągłe numeryczne, a następnie dostarcza szczegółowe raporty HTML na podstawie ich charakterystyki.\n",
    "10. **`_analyze_binary(df, column, input_value)`**, **`_analyze_categorical_numbers(df, column, input_value)`**, **`_analyze_categorical_strings(df, column, input_value)`** oraz **`_analyze_numerical_continuous(df, column, input_value)`**: Generują treść HTML dla różnych typów cech (binarnych, kategorycznych numerycznych, kategorycznych tekstowych i ciągłych numerycznych), dostarczając szczegółowych informacji na temat wartości pacjenta, jej częstości w zbiorze danych oraz dodatkowych informacji statystycznych (takich jak porównania z średnią, medianą i odchyleniem standardowym dla cech ciągłych).\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abb463433139b2ee",
   "metadata": {},
   "source": [
    "## Opis obiektu klasy medaid\n",
    "Klasa będąca głównym obiektem narzędzia. Umożliwia ona wczytanie danych, przetworzenie ich, trenowanie modeli, zapisanie wyników oraz generowanie raportów.\n",
    "#### Metody:\n",
    "-  `__medaid()__` Konstruktor klasy MedAId, inicjalizuje obiekt z podanymi parametrami.\n",
    "    - dataset_path: ścieżka do pliku CSV z danymi.\n",
    "    - target_column: nazwa kolumny zawierającej zmienną celu.\n",
    "    - models: lista modeli do przetestowania (domyślnie [\"logistic\", \"tree\", \"random_forest\", \"xgboost\", \"lightgbm\"]).\n",
    "    - metric: metryka do optymalizacji (domyślnie F1, możliwe [ \"accuracy\", \"f1\", \"recall\", \"precision\"]).\n",
    "    - path: ścieżka do zapisu wyników.\n",
    "    - search: metoda optymalizacji hiperparametrów (domyślnie random).\n",
    "    - cv: liczba podziałów w walidacji krzyżowej (domyślnie 3).\n",
    "    - n_iter: liczba iteracji optymalizacji hiperparametrów (domyślnie 20).\n",
    "    - test_size: rozmiar zbioru testowego (domyślnie 0.2).\n",
    "    - n_jobs: liczba rdzeni procesora do użycia (domyślnie 1).\n",
    "    - param_grids: słownik zawierający siatkę parametrów dla każdego modelu.\n",
    "    - imputer_lr_correlation_threshold: minimalna korelacja dla imputacji regresją liniową.\n",
    "    - imputer_rf_correlation_threshold: minimalna korelacja dla imputacji za pomocą Random Forest.\n",
    "    - categorical_threshold: próg do rozróżnienia kolumn tekstowych od kategorycznych (jeśli stosunek unikatowych wartości do wszystkich wartości w kolumnie jest większy niż ten próg, kolumna jest uznawana za tekstową i usuwana).\n",
    "    - removal_correlation_threshold: próg korelacji dla usuwania silnie skorelowanych kolumn (bez zmiennej celu, pozostaje tylko jedna kolumna  z grupy silnie skorelowanych)\n",
    "- `preprocess()`przeprowadza preprocessing danych.\n",
    "- `train()` przeprowadza preprocessing i trenuje modele na danych treningowych, zapisując najlepsze modele oraz ich wyniki.\n",
    "- `save()` zapisuje modele do pliku medaid.pkl w folderze `medaid#/`. \n",
    "- `report()` wykonuję funkcję `generate_report()` z klasy `MainReporter` zwracającą raport w formacie HTML z wynikami analizy danych i modeli opisane w sekcji `reporting/`\n",
    "- `predict_explain(input_data, model)` generuje raport wyjaśniający prognozę modelu na podstawie danych wejściowych będących pojedynczym wierszem ramki danych (bez kolumny target).  Jeśli model lub dane wejściowe nie są podane, funkcja używa domyślnych wartości - pierwszego modelu z listy `best_models` oraz pierwszego wiersza z ramki danych."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eef000550ff85a24",
   "metadata": {},
   "source": [
    "## Przykładowe Użycie\n"
   ]
  },
  {
   "cell_type": "code",
   "id": "e0fef5795c89d9d8",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:08:43.280113Z",
     "start_time": "2025-01-19T19:08:37.048386Z"
    }
   },
   "source": [
    "from medaid.medaid import MedAId"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "code",
   "id": "da8fcdf6de712851",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:08:43.323862Z",
     "start_time": "2025-01-19T19:08:43.294304Z"
    }
   },
   "source": [
    "aid = MedAId(dataset_path='./data/multiclass/Obesity_Classification.csv',\n",
    "             target_column='Label',\n",
    "             metric=\"f1\",\n",
    "             search=\"random\",\n",
    "             path=\"\",\n",
    "             n_iter=10,\n",
    "             cv=3)"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "8cc6500ae78740d2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:09:07.154362Z",
     "start_time": "2025-01-19T19:08:44.594655Z"
    }
   },
   "source": [
    "aid.train()"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "logistic progress: 100%|██████████| 10/10 [00:09<00:00,  1.05it/s]\n",
      "tree progress: 100%|██████████| 10/10 [00:00<00:00, 20.69it/s]\n",
      "random_forest progress: 100%|██████████| 10/10 [00:04<00:00,  2.44it/s]\n",
      "xgboost progress: 100%|██████████| 10/10 [00:01<00:00,  9.35it/s]\n",
      "lightgbm progress: 100%|██████████| 10/10 [00:02<00:00,  3.91it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Finishing up...\n",
      "\n",
      "==========  Training complete  ==========\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "f48d37cb3b691ae3",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:09:07.256199Z",
     "start_time": "2025-01-19T19:09:07.180229Z"
    }
   },
   "source": [
    "aid.save()"
   ],
   "outputs": [],
   "execution_count": 4
  },
  {
   "cell_type": "code",
   "id": "c57680593a096348",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T19:09:07.363918Z",
     "start_time": "2025-01-19T19:09:07.266743Z"
    }
   },
   "source": [
    "aid.report()"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "code",
   "id": "c5d59ea83be4de1d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:50:58.397173Z",
     "start_time": "2025-01-19T18:50:58.283517Z"
    }
   },
   "source": [
    "aid.models_ranking()"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "           model  best_score        f1  accuracy  precision    recall  \\\n",
       "0           tree    0.964987  0.964987  0.965517   0.977011  0.965517   \n",
       "1  random_forest    0.964987  0.964987  0.965517   0.977011  0.965517   \n",
       "2        xgboost    0.952107  0.952107  0.954023   0.972414  0.954023   \n",
       "3       lightgbm    0.919000  0.919000  0.917898   0.942877  0.917898   \n",
       "4       logistic    0.893050  0.893050  0.895320   0.905304  0.895320   \n",
       "\n",
       "   test_best_score   test_f1  test_accuracy  test_precision  test_recall  \n",
       "0         0.953047  0.953047       0.954545        0.961039     0.954545  \n",
       "1         0.953047  0.953047       0.954545        0.961039     0.954545  \n",
       "2         1.000000  1.000000       1.000000        1.000000     1.000000  \n",
       "3         1.000000  1.000000       1.000000        1.000000     1.000000  \n",
       "4         0.953047  0.953047       0.954545        0.961039     0.954545  "
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>best_score</th>\n",
       "      <th>f1</th>\n",
       "      <th>accuracy</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>test_best_score</th>\n",
       "      <th>test_f1</th>\n",
       "      <th>test_accuracy</th>\n",
       "      <th>test_precision</th>\n",
       "      <th>test_recall</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tree</td>\n",
       "      <td>0.964987</td>\n",
       "      <td>0.964987</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>random_forest</td>\n",
       "      <td>0.964987</td>\n",
       "      <td>0.964987</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.977011</td>\n",
       "      <td>0.965517</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>xgboost</td>\n",
       "      <td>0.952107</td>\n",
       "      <td>0.952107</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>0.972414</td>\n",
       "      <td>0.954023</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>lightgbm</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.919000</td>\n",
       "      <td>0.917898</td>\n",
       "      <td>0.942877</td>\n",
       "      <td>0.917898</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>logistic</td>\n",
       "      <td>0.893050</td>\n",
       "      <td>0.893050</td>\n",
       "      <td>0.895320</td>\n",
       "      <td>0.905304</td>\n",
       "      <td>0.895320</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.953047</td>\n",
       "      <td>0.954545</td>\n",
       "      <td>0.961039</td>\n",
       "      <td>0.954545</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "fec2eb7b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:51:02.819639Z",
     "start_time": "2025-01-19T18:51:02.651070Z"
    }
   },
   "source": [
    "import pandas as pd\n",
    "aid.predict(pd.DataFrame(pd.read_csv(\"./data/multiclass/Obesity_Classification.csv\").drop(columns=[\"Label\"]).iloc[1, :]).T, model_id=0)\n"
   ],
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Normal Weight']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 7
  },
  {
   "cell_type": "code",
   "id": "5a751a8ddae3b67f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:51:22.620214Z",
     "start_time": "2025-01-19T18:51:22.434709Z"
    }
   },
   "source": [
    "aid.predict_explain(model=aid.best_models[1])"
   ],
   "outputs": [],
   "execution_count": 8
  },
  {
   "cell_type": "code",
   "id": "df38c6930d893290",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-01-19T18:51:24.661734Z",
     "start_time": "2025-01-19T18:51:24.656161Z"
    }
   },
   "source": [
    "print(aid.path)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Zosia\\Desktop\\autoML/medaid14\n"
     ]
    }
   ],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbdca25d2af8c6e0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env_p11",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
